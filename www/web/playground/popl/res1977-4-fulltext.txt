applications of high level control flow k rosen computer sciences department ibm thomas j watson research center heights new york abstract control flow relations in a high level language pro gram can be represented by a hierarchy of small graphs that com nesting relations among statements in an algollike syntax with relevant caused by goto or leave statements applications of the new style of representation include denotation al semantics data flow analysis source level compiler and program proving introduction of course we can describe control flow in a program by tracing a path in the control flow graph of the program but what is the graph of a program in an algollike high level language how is it related to the source text can goto or leave statements be handled how can sets of paths that are similar from the users viewpoint be described suppose the program is changed how can we update the graph and the results of analysis by a program prover or an optimizing compiler must we start from questions like these have led to a new representation of control flow in high level language programs section the standard low level flowchart tion of control flow and it with the use of a high level flow graph and reduced some applications of the new style of representation are sketched in sections section shows how denotational semantics can with goto while avoiding continuations section local data flow in formation and computes it bottomup section applies the new local information to global problems section applies the sections to the problem of generating concise but informative compiler at source level f of section extends method for proving partial correctness of asynchronous parallel programs ow ow to with goto and leave in the special case of sequential programs a similar but less general trick is proposed by wang wa high level control flow the restriction to classical structured programming that limited the of axiomatic systems for program proving in the style introduced by hoare h the restriction is only partially relaxed in ch two principles that have this work should be the first is that computers are not people there is little reason to expect computer processing of large structures to be by representations that are natural when people process small structures by hand for example compare infix with notation in this example computational simplicity with intuitive but it well with mathematical in the rules defining the formal notation we have chosen to relate program to graphs in a way that is elegant though perhaps for hand proc of small programs in the hope of computer processing of large programs the example program in the next section is small enough for hand processing and is just large enough to illustrate the points we wish to make another program in this size range is in section as is shown in section high level control flow is convenient for com between a computer and a person as well as for proc by a computer alone the second principle this work is a tic version of law whatever can go wrong will but not often in particular well written programs in well designed languages will have few if any goto statements but even good programmers will use them now and then kn we conclude that methods for proving or optimizing programs should be able to handle any use of goto but that this ability should not contribute to the processing costs for the many programs free of goto moreover the complexity of our methods should rise when statements are added to a large program there should not be a change when a single goto or leave is added to a large program that previously used only single entry and exit control facilities such is by a cal approach that the informal control flow diagrams of sec for structured programs but also with control flow and mar y lm sec challenge our assumption that classical struc programming is sometimes space does not per mit a full discussion of the issues here see for some recent results that support our assumption assigning graphs to programs the usual low level flowchart representation u sec is constructed by translating a program into an intermediate text unlike the of an algollike language with structured programming facilities the instructions in intermediate text cannot be nested within each other certain sequences of instructions called basic blocks are together to form the nodes of the graph this representation is a hierarchy with a graph at the top level and sequences of instructions at the level below an example is shown in figure for a program written in notation by line numbers the next column unlike the usual shallow hierarchy the high level representation proposed here has the same depth as the depth of nesting of statements statements in an algollike syntax au places in the hierarchy are held by graphs and each graph represents a portion of the control flow information in the program these begin ms s integer external comment s will be assigned the sum of the factors of ms m p t q r integer m ms sl pl p p l tp again q p r p test if r o then zero t p m q more goto again else nonzero con if t p then s p if pq then con if m then s ml s ms done leave another goto end graphs are related to each other by means of the high level flow graph for the entire program this graph is used by the theory to relate high level analysis to concepts usually defined only for low level the smaller graphs in the hierarchy are called induced graphs descriptions of the high level control flow graph for a program are in sec r sec induced graphs are constructed more formally in r sec here the presentation is rigorous and significantly more al the sets later in this section are required to be single in r let g be a finite directed graph with a set ng of nodes and a set ag of arcs an arc c has a source sc and a target tc both of which are nodes we identify c with the pair sc tc a nesting for g is a finite partially ordered set z with a maximum m together with a set na of nodes and a set aa of arcs for each a in x the following properties are required ng and at ag a in x implies n s na and a s as c in ag has sc tc in implies o is in as for we take to be the set of all statement nodes in the parse tree with a iff tree node is a descendant of tree node a we statement labels with the tree nodes they identify so that test are said to be in with rr and zero s test for each a in x for let na a leaving a u u and construct appropriate arcs for example there are arcs from entering test to zero and to entering nonzero arcs from zero and from leaving nonzero to leaving test and an arc from entering more to entering again the example of just sketched for is the high level control flow graph for which combines syntactic nesting with the details of control flow a nesting structure and exits consists of g and z as in together with for each a in x sets of designated and designated s na and s na such that s tr in n nd s and n nd s and exit sets are defined by sc sc en i for all statements in we take entering a and leaving a other and exits are added by escape or jump statements such as the leave used as in wu p and the in we can find and without constructing g all we need is the parse tree and the ability to the label in goto with as a member of given a nesting structure with and exits consider any a in n in and p in let n p if there is a path from n to p in g only nodes of na and n p o otherwise these path bits can be computed bottomup beginning with choices of a that are minimal in path bits for a can be determined from previously computed path bits for parts p of a where al y a for part for a test is zero nonzero as in r sec we construct the induced graph ga for each a in the set of nodes in ga is no u aa u where for entering real arcs of ga is for each in there is a set of arcs n p i n e p e exit n p the total set of arcs is g u u pe part with the obvious definitions of sources and targets some arcs are both real and let al be the statement con with one part then ga is shown in figure for i now let a be con so that ga is shown in figure for i more generally if a is any one part conditional statement if then in any program and if has only entering as an and leaving p as an ei h ga is as shown in figure similarly for the other control structures of classical structured programming sec escapes like leave and jumps like goto may be used within or elsewhere in the program ga only depends on the relation between a and its parts the induced graph construction automatically determines whether ga is like the simple diagrams of sec or whether the escapes and jumps in the program are relevant to cr for example g for a is as shown in figure figure shows for n and it is roughly twice as large as figure but figure the control flow analysis among instructions that identifies basic blocks and anything not reachable from the to similar analysis of figure leads to the compressed induced graph shown in figure in general whenever an induced graph is large we can go beyond r by it according to rules like those used to construct low level the formal construction follows given a nesting structure with and exits for a graph g consider any a in z and the induced graph ga by applying rules until no further changes are possible if n is a node in ga not reachable from at least one to a then delete n and all arcs c with sc n or tc n a node n in ga is flow trivial iff both n e u and there are unique arcs x y with if n is flow trivial then we it delete n x y and add an arc z from sx to ty the operation is like instructions into basic blocks denotational semantics it is natural to think of a program statement a as meaning a partial function from storage states to storage states in classical structured programming the meaning of a is quite determined by the meanings of its parts and by the production applied to generate a the classical case is important but not universal practical structured programming kn wu za requires escapes and perhaps a few jumps in a large program with a few jumps it should be possible to assign meaning bottomup in an almost classical way without a major change in semantic style such as introduction of continuations sw such a semantic style is easily with the help of section the key is simple instead of what a means we ask what a n p means where n is an to a and p is an exit from a in practical structured programming the number of such triples is often larger than x but not larger for many of these triples the meanings follow from elementary observations in general h n p o implies that a n p computes the empty map in many programming languages the syntax is such that p c and sc p implies tc e na so that a p p computes the identity map if p is in n in particular only when ha n p and n p is there any question about the meaning of a n p in the statements give rise to triples in need of analysis here now consider any graph g together with a storage state trans formation for each arc and a nesting structure with and exits that satisfies we assume determinism arcs with a common source are assigned transformations with disjoint domains given the induced graph ga the transformation for each real arc in ga and previous y determined meanings for all triples no po such that is a part of a we find that the meaning of a n p as a storage state transformation is determined the usual least fixpoint considerations are required if ga has cycles tions are partial functions and when ordered by inclusion between functions as sets of ordered pairs have appropriate completeness properties see ma ch mr for details on the machinery in particular the partial functions form a coherent mr def poset local data flow analysis for analysis to support a correctness proof or an optimization it is important to compute meanings that are much simpler than storage state transformations for example we could let the mean ing of a n p be the set of variables whose values can be modified by an execution of a that at n and leaves at p where can refers to all flow paths this set mod a n p the previous section applies equally well to this kind of meaning more over consider con and con in with induced graphs shown in figure it is easy to show that ai leaving ai leaving i the work of deriving need not be repeated for i in foreach program time need recognize that a is a one part conditional statement with a related to in the manner of classical structured programming then the meaning of a can be derived from the meaning of by into the equation entering a leaving a mod leaving derived at the time of language definition when we draw figure without the i subscript now consider in with induced graph shown in figure escapes and jumps the graph but only the statement is r sec and the sets mod p for p leaving and for p entering done can still be found by into equations derived at the time of language in general questions as to what statements can or cannot do to variables or expressions are local data flow questions they can be of statements not just the minimal ones in that roughly to instructions in an intermediate text local data flow questions ultimately refer to the high level control flow graph g and to strictly local information about what can or cannot when control flows along each arc we can answer many such questions by considering the smaller induced graphs and computing bottomup when a statement is encountered we can into a known equation without even considering the in graph we used the elementary example of mod and one part conditionals to illustrate the method the potential are more apparent when the equations like for various questions and control operators are considered details are in r for three important questions mod as above pre the variables that can be preserved and use the variables that can be used of the statements in only t fails to be only for r do we need to trace paths in an induced graph at proof time or compile time for the same reasons that the usual low level analysis techniques can use basic blocks rather than instructions as nodes we can analyze the compressed induced graph instead whatever graph analysis technique one would use in figure to determine whether can modify the value of its input ms the same technique can be used in figure instead which is only half as large due the local information derived for can then be applied to find local information about calls on in other programs recursive procedures lead to a problem there are circular dependencies in the family of equations like derived for a program with recursive procedures it can be shown that correct and possible mod pre use information is obtained by finding the least fixpoint of the family of equations details and a full discussion of the are in global data flow analysis local data flow information was in section when local information is available for all triples a n p then high level versions of traditional global flow problems can be solved as with low level a global problem is an at to assign information to nodes that summarizes either what can happen on some paths or what must happen on all paths the set of paths considered for each node n iu the high level control flow graph is either the set of paths to n from nodes in or the set of paths from n to nodes in recall the details for live variables are in r sec and it is clear that traditional constant propagation or available expressions hu sec can be similarly handled the more semilattice versions of these problems gw are under study as might be expected situations where f x a y fx a fy are such is fairly common sec and it changes to in the induced graph theorem of r sec despite this technical we can find an acceptable assignment gw p of information to nodes in the high level control flow graph by with induced graphs only we are now to generalize the symbolic analysis by so as to move much of the work backward from compile time to the time of language definition as is done in r for less flow problems a new compiler style is beginning to ca ha kn l source text and machine code will both appear as of an intermediate language high and low level constructs compilation will consist of gradual expansion from relatively high to relatively low level within the intermediate language with of analysis and optimization in particular special case code generation will be unnecessary because systematic optimization at all levels will do at least as well ca these compilers will update data flow information to reflect program changes due to optimization so as to the code nearly as well as a good programmer could the syntax di high level analysis sketched here is particularly oriented toward such compilers we try to hold down the cost of initial analysis and later updating for well written programs the well known cost bounds deal only with initial analysis and no explicit bounds on total cost are available for any data flow analysis method another to a direct cost comparison becomes apparent in the next section high level analysis yields a great deal of information that is useful for to extract this in formation from the results of low level analysis requires more work compiler much of the information so far is of obvious in understanding and maintaining a program the and exit sets in and the path bits m in display the effects of any from classical structured program ming they do this at source for each statement a low level flowchart like figure the control flow between basic blocks in one that has no simple with the source text for example the statement test includes nodes in figure and part of an even though test is rather the root of a large parse tree it cannot be with the usual shallow hierarchy unless we open up a node to reveal the sequence of instructions within a block pro in practice the situation will often be worse will be larger and will have that cannot be on a page the local and global data flow information from sections and is clearly useful for purposes or for program proofs sec and f f explain how to global flow problems such as live variables to detect data flow such as an uninitialized use of a local variable as they imply it is helpful to the programmer that b a can be reached before a is initialized but much more helpful to the with an example path this happens now suppose that b a occurs in the context context a o else change b a where and are large and statements such that for y and for y a e entering y leaving y to trace an path from a point corresponding to entering context to a point corresponding to change in a low level flowchart would be irrelevant details of paths through and would be included high level languages should the programmer of the need to read low level programs at least when fine of run time performance is not an immediate issue the exclusive use of low level control and data flow analysis methods such unless we choose to have data flow that are much less informative than is desirable programmers can with exclusively low level but there is in a new language if the corresponding debugging tool back to me in or sp p similar remarks apply to program proving when escapes and jumps are permitted in the induced graphs ga for a context and a we can easily and naturally display short paths that characterize all the paths in the full high level control flow graph we begin in context with the path from entering context to entering to leaving along an arc to entering to leaving along an arc to entering change where the second arc cannot modify a the first arc can modify a but it can also preserve a therefore we provide more detail in with the path from entering to entering to leaving along an arc to leaving where all arcs cannot modify a high level analysis leads directly to concise but informative at source level when the methods of f f are applied to languages amenable to practical structured programming program proving it is convenient to consider the original values of input as in a special part of the storage state f of a tation then partial correctness ma sec with respect to predicates p q on storage states is the property that whenever a computation begins with such that pf and with q then ow w g proposes a powerful method for proving partial correctness of asynchronous parallel programs two assertions a precondition and a postcondition are associated with each a in x as in the style of proof introduced by hoare h carefully chosen assertions can lead to clear and ing proofs despite the of asynchronous parallelism we a crucial point more abstractly and much more generally so as to extend the applicability of the method we assume that the maximum t in x satisfies entering t and leaving m but none of the other constraints of classical structured programming are needed a storage state predicate cn is to be assigned to each node n in the high level control flow graph g in such a way that for all states f q and arcs c in g pf implies rq implies qq and c q implies where c q means that can be changed to q when control flows along c in sequential programming this would guarantee partial correctness and we have so far just f into the notation of section now we impose the condition ow sec for all states q and all arcs c in g such that c and n are in distinct parallel processes and and f c t implies cn an assignment c from nodes to assertions that satisfies as well as the conditions will partial correctness in ow g the sharing of variables by processes is restricted in ways that verification of for us the precondition and postcondition for a in a hoare style proof are a and a by directly assigning one assertion to each node in g rather than assigning assertions to each statement in we the restriction to classical structured programming wang wa proposes a similar trick for sequential programs in the case where each a in y not just r satisfies only if in is always entering a leaving a will wa assign assertions to all nodes bf g consider the program sec that has been used to illustrate what is so hard about asynchronous parallelism presents an elegant partial correctness proof for a similar program ow fig the effects of leave statements are simulated in classical structured programming the program is a less clear and less efficient than the mathematical machinery in ow cannot say much less prove that partial correctness of implies partial correctness of with and however we can prove the partial correctness of directly by an easy adaptation of ow fig the formulation of is also simpler than the original one adding lemma to the partial correctness proof leads to a total correctness proof more elegant than sec references ca jl a case study of a new code generating technique for compilers comm acm to appear ch m and hoare car program proving jumps and functions acts informatica structured new york o j dijkstra programming e w and hoare car academic press london and r a s c and rj can structured programs be efficient sigplan vol num october f rw assigning meanings to programs math proc symp f l d and lj data flow analysis in software reliability tr computer science dept university of may gw graham algorithm s l and wegman m usually linear for global flow analysis x acm ha w strategy for code generation ­ the general purpose optimizing compiler these proceedings hu m s and unman jd global flow data flow problems a simple siam j algorithm for computing h hoare car an axiomatic basis for computer programming comm acm j b and unman jd global data flow analysis and iterative algorithms j acm kn knuth de structured programming computing with goto statements lm h f and m a of control structures comm acm l db program improvement by source to source transformation proc rd acm symp on principles af programming languages january ma manna z mathematical theory of computation new york mr g and rosen bk complete posets ibm j res and bases for f l j and ld a validation error detection and documentation system for fortran programs software practice and experience to appear w ss axiomatic proof techniques for parallel grams tech rep phd thesis computer dept cornell u new york july w ss a consistent and complete for the verification of parallel programs acm symp on theory of computing deductive system proc th ann may g s s and d verifying programs an axiomatic approach properties of parallel comm acm rosen bk correctness of parallel programs the churchrosser approach theoretical computer science rosen bk ibm research data flow analysis report rc for procedural languages heights april r rosen bk high level data flow analysis to appear comm acm sp ence mj software a practice and experience sw c and cp continuations a mathematical semantics for handling full jumps tech programming res oxford u u unman jd fast algorithms for the elimination of common subexpressions informatica wa wang a an axiomatic basis for proving total correctness of goto programs bit wu w a et al the design of an optimizing new york za ct a control programming statement for natural topdown notes in computer sci mlf i i i fig induced graph for al con and a con in the dashed arc is the same picture with no i subscripts would be good for any a if then statement in classical structured programming ii j i i low level flowchart for each node is a basic block of instructions in an intermediate text not shown constructed in the usual way for each block we indicate which line numbers in give rise to instructions in that block arcs indicate and exits fig induced graph ga for a in note that leaving is not reachable from any to this graph and the graphs shown in figure belong to the infinite family of graphs induced by one part conditional statements a if then that appear in programs with various uses of escapes and jumps these graphs also belong to the infinite derived from one part con that are in practical structured programming most statements are art fig induced graph gn for n dashed arcs are but not real heavy arcs are by escapes and jumps because two of these arcs pass control from test to other parts and again of v the statement n fails to be i fig compressed induced graph for r an arc from m to p in summarizes the net effect of a path from m to p in that passes through only flow trivial nodes 