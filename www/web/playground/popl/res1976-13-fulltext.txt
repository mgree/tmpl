program transformation xerox palo alto research center hill palo alto california abstract program development often proceeds by transforming simple clear programs into complex but more efficient ones this paper ways this process can be more systematic we show how analysis of program performance partial evaluation of functions and abstraction of recursive function definitions from can be combined to yield many global transformations in a fashion examples are drawn from compiler optimization list processing very high level languages and apl execution key words and phrases program transformation program analysis partial evaluation optimizing transformations compiler optimization analysis of programs execution analysis simplification generalization evaluation in context very high level language list processing lisp apl cr categories introduction optimizing transformations provide a means for converting a clear but inefficient program into one with equivalent results but better performance characteristics certain optimizing transformations have been used for some years in the compilers for algebraic languages a survey by and allen lists and approximately such transformations languages in which the builtin operations act o n composite objects such as arrays eg apl sets eg setl or relations eg give rise to the need for additional classes of optimizing transformations there are three reasons for this the substantial which language from underlying machine makes it possible for the programmer to write simple programs for which execution yields performance the use of composite objects often makes such programs the most natural expression to write and modify of the of these languages is due precisely to the of expression from implementation for these reasons the potential from an appropriate set of optimizing transformations for these languages is substantial this paper shows how the process of program transformation can be systematic our thesis in brief is that program transformation can be made it is possible to analyze programs so as to obtain expressions for their execution performance and the complexity of their output based on between these performance goals are established these goals are used to direct the process of program is carried out by local simplification partial evaluation of recursive functions abstraction of new recursive function definitions from and generalization of expressions as required to obtain compatible thus highlevel goals or are used to guide and give coherence to the operations of local activities we expand on this brief description below our intention in this paper is we show how this approach provides a framework in which many of the optimizing compiler transformations can be placed and in this framework related transformations not commonly implemented in optimizing compilers are seen to have a natural place we show how many of the optimizing transformations for very high level languages can be obtained in a straightforward way from the program thus these techniques may find a role in the future processors of such very high level languages we hope to make a small step in identifying and techniques by which those who must be concerned with efficiency can carry out their design in a systematic fashion considerable attention has been given in recent years to the systematic development of programs formalizing the of programmers comparable attention should perhaps be to the fundamental techniques which the systematic development of programs basic ideas one means for transforming a program into an equivalent one with better performance relies on program analysis to single out the appropriate portions of the program to be rewritten by program analysis we mean the derivation of algebraic expressions which describe execution these expressions specify the programs computation cost eg execution time a m o u n t of storage used number of io requests and the programs output characteristics eg size of the result textual source of allocated storage the result probability of the result satisfying a given predicate as a function of input characteristics using program analysis techniques our transformation approach proceeds as follows obtain some idea of the minimum computation cost required to produce the inputoutput mapping being realized by the program analyze the program to determine its computation cost and relate components of the cost to specific segments of the program text find those program segments whose computation costs are not for in the of minimum cost these segments are potential sources of computational and are therefore designated as targets for simplification if the targets so designated contain multiple possibilities for simplification focus attention on the program segments having the greatest analyzed cost as the program can b e transformed to realize a significant performance improvement it must be by simplifying these the central idea we wish to present is that this approach can be systematic and thus has a place in programming methodology as well as as a basis for mechanical program transformation notation several of our example programs will be written in a syntactic variant of lisp using the following notation  the empty list is denoted by nil  constructs a list in which the first element is x and y is the list of all elements except the first  h read as head is a prefix operator which extracts element from a nonempty list to avoid the argument to h is not eg h x  t read as tail is a prefix operator which extracts all elements except the first from a nonempty list t y  is defined as  conditional expressions are written as if pl then e else if p then e else en  function definitions are written as i defining form lists of three given the following definition of append if t h e n y else consider x to y to z by the expression z analysis program analysis shows that the execution cost is p r o p o r t i o n a l to i w h e r e ix is t h e length of the list x it is useful to between the inner and outer calls on append l e t these be denoted by a and a and let the associated calls on cons be cons and cons then program analysis shows t h a t z executes x calls on cons and calls on cons analysis of the output of z shows that its l e n g t h is d i f f e r e n t i a t i n g t h e source of the which the output analysis shows t h a t calls come f r o m cons and t h a t z calls come from t h e i n p u t z comparing the execution costs internal work to the output work it is seen t h a t t h e ix calls on cons r e p r e s e n t effort these calls are being executed internally but cannot be for in the output the task of transformation is to rewrite the program so as to remove the calls on cons we refer to cons as the target for simplification transformation to remove a cons we can apply the local simplification rules h a t fl to obtain an to apply these we expand the definition of append to the point where h and t appearing in the program can be applied to cons start with z expand ie replace the call by an instantiated body resulting in then y else z the conditional ie bring the conditional expression from the argument position to outside the call on a so t h a t a is applied to the result of each conditional clause this yields if then else z expand the second call on a and then simplify we call this partial evaluation and the steps in this case are as follows consider z let denote so we are considering expanding a results in if then z else since is not null it follows that further we can apply the local simplification rules for cons to r so t h a t hr hx and t thus we h a v e removed one instance of step toward our goal we have z thus has been partially evaluated to yield if then else z because one cons is absent the evaluation of requires in the case of a nonnull x one fewer cons than the evaluation of thus is a slightly improved way of computing whenever we are with evaluating an expression of the form it is desirable to use in its place observe that the form appears as a subexpression of with the substitution of tx for x ie as z we have identified a z which is identical in form to a more global problem z we call this identification abstraction and use it to define a new recursive function in which the performance improvement of is systematically achieved we introduce to stand for z then and become if then else ignoring subscripts we have if then else as an executable definition of f since the above derivation preserves correctness it follows that z analysis shows that the execution cost for f is linear in and in particular the number of cons executed is thus the goal has been further examples some additional examples will illustrate that this approach can yield interesting results we show the problem analysis and final derivations the following program compares two arrays and and sets the boolean variable same to true if they are pairwise equal j while do same same a return same analysis shows that this requires n steps and that the result is a boolean scalar it is therefore possible that the scalar could be computed in fewer steps the entire loop is the target for simplification the a operator has the local simplification rule x a y i f x t h e n y else f a l s e which avoids computing y when the value of x determines the result we write the above loop as a recursive function and apply our transformation method using the local simplification rule we obtain a new function which when put into iterative form is s a m e t r u e while a same do same return same this requires n steps in the worst case and step in the best case if the probability that is fl p r o g r a m analysis shows t h a t t h e average number of steps is observe that this is bounded from above by fl the following has the value if n is prime and otherwise reading f r o m r i g h t to left this may be as consider n and the sequence n o b t a i n t h e r e m a i n d e r s a f t e r the elements of the sequence into n find the elements with remainder count their occurrences and test the count to see if it is if so then n is prime analysis shows that this constructs three temporary arrays each of length n b u t t h a t the o u t p u t is a single scalar transformation takes place in three stages each of which eliminates one array the final result is hn where if kn then else if n mod ko then else which constructs no temporary arrays it simply counts the number of times the remainder of n divided by k is for k from to n techniques the preceding derivations employ three techniques program analysis partial evaluation and abstraction these activities may be roughly characterized as analyzing the programs resource and output to find appropriate targets for simplification rewriting portions of the program to realize a performance improvement on the first execution of the programs loops and using these to form recursive programs such that the performance improvement is on every execution of the programs loops we now examine these in greater detail program analysis obtains expressions which describe execution behavior as a function of input characteristics eg worstcase execution time as a function of the a system which automatically carries out program analysis for simple programs is discussed in techniques implementation issues and limitations are discussed there in the interest of brevity we our discussion here to the sorts of analysis which can be produced in this way analysis is carried out for three worst and average under some assumptions about input distributions it is useful to write the expressions describing execution cost in a partially form separating out the dependence on input characteristics from the dependence on machine implementation for example the execution time of append is written as where n is the length of the first argument to append and are implementation constants the implementation constants are written as linear arithmetic expressions of the form r l p l where the are rational numbers and the denote costs of executing primitive operations for the case of append co null c i car cdr cons the lower case of a primitive operation stands for that operation denotes the action required to invoke a operation denotes access to a variable when analysis is used for the purpose of program transformations it is useful to distinguish the source of a primitive operation based on the defining function in which it appears thus denotes those created by the execution of the cons operation inside append cf the definition of append section to do this we distinguish the symbolic costs of elementary operations based on their textual position a cons inside function a is treated for the purpose of analysis as if it were distinct from a cons inside function b in the case where a defined function f appears more than once in the expression to be transformed it is useful for the purpose of analysis to treat each occurrence of f in the expression as if it were a distinct function suppose f is recursive and the expression is fy z this is treated as if it were fy z all calls to f from f and from functions called by f are treated as calls on f similarly f is treated as calling f recursively a function call within the inner f is therefore labeled f thus we can distinguish the cost of executing the inner f from the cost of executing the outer f once its arguments have been evaluated this representation of execution was chosen for its generality from it we can obtain the answer to specific questions by assigning appropriate values to the primitive operation symbols for example to obtain total execution time on a given machine let each primitive symbol stand for the execution time of the corresponding operation to obtain the total number of cons cells created let for all i be and let the other elementary operation symbols be in analogous fashion we may obtain the number of function calls out of a specific function or the computation time spent within a specific group of functions several other sorts of analysis are also of interest one class is output analysis eg determining the length of a functions output if an array or list or its range if a scalar in the case of list length it is useful to distinguish the textual source of which occur in the output eg an o u t p u t list might be of length but this is more expressed as r a such expressions are obtained by computing the output list length as a polynomial in a way similar to the execution cost analysis another class of analysis is concerned with internal operations eg the probability of a procedure returning the value true such analysis is required as auxiliary data in computing computation cost these are obtained and the results are expressed using methods similar to those for execution cost the results of analysis are employed in two ways the first method exploits between the complexity of a programs output and the computation cost of obtaining that output such represent work and the corresponding program components are therefore targets for simplification when this out a specific portion of the program it provides a criterion in some cases this may not be specific enough to further narrow the target a second method is employed this consists of goals on the basis of current performance and using the results of analysis to determine the program components causing between these goals and the computation cost for example if a program runs in n steps a goal is n steps and the target for simplification is to those responsible for the n behavior if the goal of n steps is then a second more goal will be tried ie fewer steps in the best case thus at each step the goal is taken to be the next significant performance level this selects as the target for simplification those program components which must be simplified if that performance level can be by our transformation method we stop when the computation cost is with the complexity of the generated output or when transformations fail to a goal partial evaluation partial evaluation consists of rewriting portions of a function to exploit knowledge of its arguments in the simplest case a partial evaluator takes a function p of n formal parameters n along with values k for the first k actual arguments and constructs a new function p such that k bk bn for all sets of bj t h a t is p is a variant of p specialized to the case where the first k parameters are known constants to the extent that p is a simplified version of p its computation cost is smaller here we employ an extension of this idea rather than knowing the actual values of certain formal parameters we know the function which constructs them let be defined functions of one argument for simplicity our partial evaluator will typically take an expression such as along with the definitions of and construct a new function p such t h a t k bk bn p q l b l bk bn that is p is a variant of p specialized to the case where the first k parameters are known to be computed by q qk to the extent t h a t p combines the computations of the first k arguments with each other and with the execution of p p runs faster than the sequential execution of q qk followed by p i t is useful to distinguish four of partial evaluation expanding function definitions conditionals simplifying and evaluating in context expansion replaces a function call by a instantiated copy of the function definition if p has formal parameters n then the complete expansion of is obtained as follows i let ri be the result of instantiating the body of qi with argument yi for ii in the body of p substitute ri for xi i l k and yj for xj n it is to carry out an expansion of all defined functions even to one level since this up the program size and makes difficult the recognition of subexpressions needed for abstraction instead we adopt the following method defined functions are expanded only if they can be reduced to constants or so far as necessary to expose the target for simplification to local simplification rules this into three expansion criteria el the function call which contains the target is expanded e the surrounding function is expanded as necessary to obtain surrounding context for the local simplification rule e if all the arguments and free variables of a function call are constant then the function call is expanded thus to eliminate a cons by the local simplification rule h a we expand the function call which contains that cons criterion el and also expand the surrounding function call so as to obtain an h operation which may be applied to the cons criterion e typically a function expanded in this way contains conditional expressions eg controlling recursion suppose such an expanded function occurs as the argument to an outer function say f we then have an expression such as fa if pl then e else if p then e else en where a the conditional expression and v are the first second and third arguments to f the conditional consists of the conditional tests out of the argument position to the surrounding scope this yields a conditional expression in which f is applied to the result of each conditional clause if pl then else if p then else this creates new specialized function because they are specialized their further partial evaluation may lead to to illustrate the steps of partial evaluation we return to the example of section and consider z since the cons in a is chosen as the target for simplification a is selected for expansion by criterion el from the definition of a we obtain then y else z the conditionals we obtain if t h e n else z the target for simplification cons is now in an argument position expansion criterion e selects the surrounding function a for expansion thus z is expanded into if then z else z which is for simplification in regard to simplification we take the following operational point of view let la be the cost of computing expression a then expression is simpler than expression a if i for some assignment of values to variables and for all assignments of values to variables by this criteria the  following are simplifications pl a p if pl t h e n p else f a l s e h e f a l s e if f a l s e t h e n e i else e e if p t h e n e else e e applying these sorts of local simplification rules to the above expression results in z thus the partial evaluation of z yields if t h e n else z we denote this as z if then else that is a means that a can be partially evaluated to yield and thus if the computation a terminates then the computation terminates and yields the same answer an additional of partial evaluation not illustrated by the above example is evaluation in context this consists of using information derived from conditional expressions to in local simplification evaluation in context arises when an expression embedded within a conditional is selected for the predicates on test branches leading to that expression are known to be true consider for example the expression where m computes the maximum of the s e t as follows if then b else if then else expanding in and simplifying yields if then true else if then else where bb has been simplified to true next we expand the expression in so doing we can use results of the tests leading to this point so we know a we call these tests context conditions for the expansion of expanding this in context yields if then false else if then else this follows because value of the first conditional expression can be simplified to false in the context to express the use of context conditions in partial evaluation we extend the above notation and write a in context p similarly we extend the definition of simpler to include context conditions is simpler than a in context p if for some assignment of values to variables which satisfies p and h for all assignments of values to variables which satisfy p abstraction abstraction consists of identifying which are identical in form to more global problems and using this identification to construct the definitions of recursive functions suppose that a i f p t h e n e e l s e r when a and fl are expressions and r is an e x p r e s s i o n i n v o l v i n g ft s u p p o s e t h a t t h e r e is some s u b s t i t u t i o n e which carries a into fl ie we say t h a t a is the goal is the and fl is a s u b s t i t u t i o n i n s t a n c e of a rewriting the above a if p then e else let f be the set of variables in a let ff be defined by f i f p t h e n e e l s e it follows that a ff that is if the computation a terminates then the computation f terminates and their values are equal the reason for introducing such a definition is to obtain a performance improvement hence we construct such a definition f and use it to compute a only when f is computationally simpler than a if a if p t h e n e e l s e for all a s s i g n m e n t s of v a l u e s to v a r i a b l e s t h e n a f i f also a if p t h e n e e l s e for s o m e a s s i g n m e n t of v a l u e s to v a r i a b l e s t h e n a for that assignment thus f is simpler than a in the general ease comparing the costs of a with if p then e else is carried out by analyzing the computational costs of the latter expression since some of its have been previously analyzed and since the analysis technique the analysis of when dealing with a larger expression in which they are contained such analysis is generally easier than the original analysis of a in a commonly occurring case a cost comparison can be carried out more directly to explain this it is necessary to first the relation between partial evaluation and c o m p u t a t i o n cost if a t h e n m u s t terminate whenever a terminates but there is no that s cost is less than in obtaining from a two are at work local simplification to make simpler than a thus if a contains if p then e else e and this is simplified to e then will be simpler by the cost of p plus the cost of an if actual arguments when expanding functions to make more costly than a when the arguments are complex expressions and must be executed more than once thus if a contains x and if f is expanded and simplified to if then gx else gx then will be more costly since it executes gx twice in the expanded body of f rather than once as the argument to f because the combined effect of these two may be complex the relation of a to is determined in the most g e n e r a l case b y a n a l y z i n g often however the second does not occur after local simplification the arguments to an expanded function appear at most once on each execution path through the expanded portion of the function body in such cases the cost of differs from the cost of a only as local simplifications may have taken place if there have in fact been any simplifications then is necessarily simpler than a if a new function f is defined as specified in then f is known to be a better way of computing the same result than a computes it is important to that the goal for abstraction need not be the original toplevel problem in general the goal a will be some subexpression which arises in the course of partial evaluation and the fl will be the matching subexpression let p be the context condition for the evaluation of a the criteria for abstraction are sa a in c o n t e x t p sa there is a substitution e such t h a t sa is simpler than a in context p sa po is true at the points in zx where fl appears the last of these criteria may require further explanation in order for a fl to be identical in form to a goal a the context conditions used in partially evaluating a must be true at each of in a we refer to this as the context conditions an example will illustrate the importance these considerations let m be the maximum of defined if then c else if then else evaluation in context shows that in context bc if then false else if then else we match against with the substitution checking the context condition bc under the substitution e requires showing that at the expression which is true since bc a implies similarly we match against with the substitution the context condition bc is easy to check since it is unchanged by this substitution thus abstraction can be carried out we let stand for in context bc meaning that f is defined only when its first argument is less than its second we have if then false else if then else simplifying this false since the only way f can terminate is by returning false thus in context bc false this may be read as bc stated as a theorem this is however in program optimization one does not have explicit statements of desirable theorems as input that the transformation method obtains this directly from the expression and definitions is of interest generalization a somewhat subtle point in abstraction is the way in which argument positions are generalized we first consider the generalization of constant arguments consider an expression of the form f and suppose that the target for simplification is inside g so t h a t g is to be expanded followed by a partial evaluation of f it would not be desirable to uniformly replace all constants by new individual replacing by some new f might be simplified in its partial evaluation in the case t h a t its first a r g u m e n t is known to be an extreme case would be where f is partially evaluated to a constant on the other hand there are cases in which matching is blocked by the presence of different constants in the same argument position of a goal expression and a for example partial evaluation of f might lead to an expression in which appears hx cannot be matched against so abstraction is when a match fails because of the presence of a constant in the goal generalization is employed argument positions which are constant in the goal and different in the are replaced by new individual variables then the generalized goal expression is partially evaluated if the result is similar to the previous result the match will succeed for example suppose fo is generalized to fz and t h a t partial evaluation of this leads to an expression in which appears the match is successful with the substitution a similar situation is caused by the multiple of an individual variable in a goal expression consider for example k where the variable k appears twice it would be to adopt the uniform policy of generalizing this to z and then to optimize this for it might be the case that z has a simple partial evaluation and abstraction for but not otherwise i t would be equally to accept only matches of the form el since it might be the case that no such occur suppose for example that the first match in the partial evaluation of k was the subexpression k and that all subsequent matches had the form k for j we adopt the same solution here as for constants the matching process constructs a list of substitutions if a match fails because the substitutions for a variable are incompatible ie e l x and ex where then the conflicting of the variable in the goal expression are generalized to distinct individual variables in summary the strategy for generalization is to delay so doing until required by abstraction to generalize as by the match and then to determine the effect of this generalization by the partial evaluation an example will show the importance of generalization and how generalization with evaluation in context consider for example the function fn if n v nl t h e n else analysis shows that fn takes exponential time we start with the right hand side of the definition if n v n l t h e n else analysis shows that the cost of fn is the largest component so it is selected for partial evaluation expansion uses the context condition n a nl after conditionals and simplifying the result is if n v nl t h e n else if n t h e n else taking as the goal and fn fn as the we attempt to match this fails since the constant does not match the implicit constant in we generalize the goal to partially evaluating fn in context n a nl we get i f n t h e n kl else k l f n k f n again the match fails due to a constant argument in the goal and again we generalize taking k f n l in c o n t e x t no a nl as the goal and partially evaluating we get if n t h e n kj else the match is now successful with the substitution kj under this substitution the context conditions are true at the calls on f so we can carry out abstraction define let stand for in context a if n t h e n kj else k nl thus we have that fn can be computed as if n v nl t h e n else gn which executes in linear time further examples in this section we present three examples to illustrate particular points of interest each example is labeled with the points it illustrates we our to a statement of the program the key points of the processing and the result omitted steps are either straightforward or of points illustrated elsewhere treatment of w h i l e loops special purpose local simplification rules evaluation in context checking context conditions in abstraction consider the while loop while p do if q then r else s where the value of q is by r and s ie the t e s t is taken in the same direction on the il st iteration as on the ith let be a vector of the variables appearing in or s it turns out that processing is simplified if such iterative programs are converted to functional form viz f where f if p then else i f q t h e n fr else provided that p and q have no side effects let the number of times the loop is executed be n the contribution of q to the c o m p u t a t i o n cost is qn suppose analysis shows this is large so that q becomes the target for simplification since the value of q is unchanged by s and r we have two local simplification rules qr q and qs q transformation proceeds as follows start with and expand the functions which contain the target for inner calls on f f if p then else if q t h e n i f pr t h e n r else i f qr t h e n else else i f ps t h e n s else i f qs t h e n else fss we now proceed to evaluate in context and apply local simplification rules using in the context while in the context thus f if p t h e n e l s e i f q t h e n i f pr t h e n r else e l s e i f ps t h e n s e l s e fss comparing this to we have fr in c o n t e x t q i f pr t h e n r else fs in c o n t e x t q i f p s i t h e n s else fss we can match against fr with the substitution er for the match to succeed it is also necessary to check that the context conditions of the goal are also true for the here this requires checking t h a t the context condition q is true after the substitution at the point where is invoked since this is m a n i f e s t l y true matching against fs is similar letting fr and fs stand for fr and fs respectively we have the following definitions if pc t h e n else i f p t h e n else fss substituting these into and converting to iterative form the final result is if p then if q then r while p do r else s while p do s the contribution of q to the computation cost has been reduced from to iq so the goal has been the transformation of to this form is generally loop in compiler optimization that this is a straightforward application of the general transformation method is of interest the utility of carrying out the derivation in functional form should be apparent successive transformations with performance goals theorem proving to enable a local simplification rule we use the following definitions for set membership m and set union u where sets are represented as lists i f t h e n f a l s e else if then true else i f t h e n y else if then else consider the expression mb ie in more conventional notation analysis shows that this has a best case time proportional to and a worstcase t i m e of using the result is a boolean thus the elimination of the is taken as the goal in particular the cons in u is the target for simplification we start with mb expand the function call u which contains the target for simplification the conditional and partially evaluate the third invocation of only one which simplifies the result is if then else if then mb else if then true else mb we have found a mb in its two occurrences can be matched against the original expression mb this allows definition of a function to stand for mb if t h e n else if then else if then true else analysis shows this has a t i m e of and a worstcase time of b u t now uses no our first goal has been this can be carried one important step further the worstcase factor of is due to the expression this becomes the next target for simplification we have the local simplification rule i f p t h e n e else e e this could be employed to eliminate if we could exchange the order of the second and third clauses of the conditional such an exchange is legal so long as the value of the program is not affected ie if pl then e i else if p then e else e if p then e else if pl then e i else e provided that if pl is true then p terminates and pl a p ele that is when both predicates apply the values produced are identical to eliminate we must prove a d this is a simple theorem and in fact has been proved using the program verifier described in thus we have if then else if then true else which has constant time in the best case and t i m e xy i n t h e w o r s t case t h u s a t t a i n i n g the second goal note that the final program is equivalent to if box then true else as expected generalization decomposition of complex expressions this example has its origin in the processing of apl we use several apl operators which may be to the reader for ease of we restrict usage to scalar and vector arguments and assume that all vectors are as required thus their definitions are simplified m the vector n xy the concatenation of x with y y the partial sums of y ie the vector yl xy the compression of y by x ie s e l e c t s t h o s e e l e m e n t s yi s u c h that xl and forms a new vector of the selected elements y the negation of y the ith e l e m e n t of t h e r e s u l t is if yi is and if yi is not t h e o p e r a t i o n i f x is a scalar and y a vector the result is a vector of elements yi mod x the other binary operations on scalars are extended in the same way ay the of y ie the of all elements of y to simplify the discussion and carry it out in the same framework as the other examples we treat apl vectors as if they were lists t h u s ln is t r e a t e d as in w h e r e is t h e function defined i n k i f kn t h e n nil else the storage for m is therefore n which is our a vector of n elements as in an actual apl implementation suppose y is an array of ls and os the following expression suggested by alan tests whether all sequences of ls are of even length this may be read from right to left as consider the vector y with a form a vector of partial sums select from that vector all elements whose corresponding element in the vector y is take the of that vector when divided by construct a vector whose ith element is or as the ith remainder is o r f o r m t h e l o g i c a l a n d of a l l e l e m e n t s that will be true if and only if all sequences of ls in y are of even length this constructs temporary arrays and makes passes over y and the temporaries in our lisp notation this is written as s where if t h e n y else if t h e n nil else ny if then nil else if t h e n nil else if hx then else ex if then nil else mod rx i f t h e n t r u e else if hx then false else optimization proceeds from the inside out transforming argument expressions substituting the transformed arguments in place of the original ones and using these in transforming enclosing operations we begin with s which corresponds to y analysis shows that this computation takes that the length of the output is and that the cells the output come from s the executions of cons in a are being these become the target for simplification taking s ay expanding a and partially evaluating s results in an expression containing the first occurrence of in the goal must correspond to hy in the so the match fails generalization of the first argument position to a new individual variable k is required observe that the second occurrence of in the goal matches a in the so this is by generalization generalization the new expression consideration is sk ay after under expanding a partially evaluating s and abstracting on a results in sk ay where f is defined if n u l l i t h e n else this requires calls of cons to yield a result of new cells so the goal has been next fy is substituted for s ay in and the decomposition process is repeated the second expression for optimization is again analysis shows that the executions of cons in a are being lost transformation yields gy where gy i f t h e n else next the expression fy is considered analysis shows that the executions of cons in both g and f are being lost transformation yields hy where if t h e n else if hy then ty else ty successive steps consider then n of that result and then r of that result in all the optimization process is carried out six times the final program is jy where if a k then false else if then true else if hy then ty else if k mod t h e n false else which constructs no temporary arrays and makes at most a single pass over y this may be directly transformed to the iterative program k while do if hy t h e n else if k mod then return false else if k mod then return false else return true conclusion i relation to other work mechanical program analysis is discussed in an interactive system which provides to the in program efficiency is discussed in a number of partial evaluators have been implemented for various purposes a good survey of partial evaluators and their applications may be found in program transformations which preserve correctness with respect to given assertions are discussed in the notion of loop expansion followed by abstraction to obtain a computational advantage is discussed in in the context of generating efficient code for machines with parallel operation capabilities more recently and have employed the idea that a recursive function call can be formed when in the course of working on a problem a is generated that is identical in form to the toplevel goal the use of and optimize the execution of apl programs is discussed in further studies in the optimized interpretation of apl expressions are presented in the major contribution of this work is in the use of program analysis to direct the transformation process using analysis and performance goals to select a target for simplification and then using this to direct the program expansion steps during partial evaluation seems to be a natural and useful technique another contribution is the use of context conditions in partial evaluation to establish enabling conditions for local simplifications and associated with this the checking of context conditions in abstraction a third contribution is the treatment of generalization in abstraction delaying generalization until required and then generalizing as by the match appears to be a promising approach while the techniques we have presented can yield some interesting results it would be a to their capabilities they are limited in effect to the transformation of one program to a better one cases in which the inputoutput mapping can be better realized by a different algorithm are beyond the scope of this method for example we can see no way to transform a definition of to a version of quicksort where change of algorithm is required program synthesis from inputoutput specifications appears to be a more natural way to if such synthesis were by considerations derived from mechanical program analysis even within the of these techniques there are which further investigation as an example consider a variation on example an apl expression which counts the number of less than n is read this from right to left as consider the n by n matrix obtained by considering the of all pairs of elements from the arrays n and n test for equality of the with and form a new matrix of the test results sum the columns of the resulting matrix test for equality of the sums with count the number of columns whose sum is exactly this constructs two n by n temporary matrices and two vectors of length n the result is a scalar analysis and subsequent transformation yields mn where if kn then else if then else if jn then s else if k mod j t h e n else this achieves a considerable storage since it constructs no temporary matrices or vectors however two remain first the function does not terminate until jn which requires time n inspection shows that if s is ever negative then h must be false thus inserting a leading test if s then false would leave the inputoutput mapping unchanged but typically lead to a performance improvement second the test jn can be to jk since k mod jr for jk however we can find no entirely satisfactory set of transformations that would lead to these changes in t h e interest of brevity we explain apl only to the extent required for understanding the examples the original definition by is given in a description of the apl system may be found in our notation for apl expressions differs from the apl systems in that we use lower case letters for variable names there should be no confusion between to denote the cost of computing the expression a and xi to denote the length of the list x context and the argument type will indicate which is intended the following are standard in formal logic a substitution is a set of the form n where the i are variables and the ei are expressions let be a substitution and a an expression then ao is the expression obtained from a by simultaneously replacing each occurrence of vi by ei it should be pointed out that there are evaluation techniques which defer evaluation of arguments until they are needed and store the result so an argument is evaluated at most once however such techniques require that the argument be used in the body exactly as it appears as an actual parameter in partial evaluation we wish to carry out simplifications eg x i gx so t h a t such techniques are not directly applicable more recent studies show of being to such situations but additional research seems required to the relation between deferred evaluation local simplification and function expansion acknowledgments my interest in the technique of partial evaluation coupled with abstraction was by discussions with burstall and john these discussions raised several of the questions in this work examples and are due essentially to dijkstra who presented the versions before and after transformation as being hard to compare the challenge by these examples was a motivating force in exploring the techniques presented here several of the apl examples were provided by alan our discussions as to the relative of transformations vs his evaluation techniques for apl have been and references p an apl machine stanford linear center acm sigplan symp on very high level languages sigplan notices april allen fe and j a of o p t i m i z i n g t r a n s f o r m a t i o n s in r ed design and optimization of compilers prenticehall b a t t a r e l g et al optimized interpretation of apl statements in p and j eds apl northholland l et al a partial evaluator and its use as a programming tool dept of computer sciences university rs and moore js proving theorems about lisp functions jacm jan burstall rm and j some transformations for developing recursive programs int conf on reliable software ieee computer society april cl and lee r symbolic logic and mechanical theorem proving academic press new york te and b a laboratory for the study of programming conf proc vol j and c two languages for program efficiency cacm june dijkstra ew notes on s t r u c t u r e d programming in oj ew dijkstra and car hoare eds structured programming academic press j high level operations in automatic programming in sl correctness preserving program transformations second acm symposium on principles of programming languages jan p and morris a lazy evaluator csl xerox palo alto research center august aw et al final report for the information system theory project applied data research inc new york ke a programming language john and sons inc la and b lisp as the language for an incremental computer in ec berkeley and dg eds the programming language lisp its operation and applications mit press cambridge manna z and r knowledge and reasoning in program synthesis stanford research inst park ca s a p l reference manual science research associates inc ea programming tool for management of data bases proc second int joint conf on artificial intelligence computer society schwartz automatic and optimization of setl in j correct and optimal implementations of recursion in a simple programming language dec b mechanical program analysis cacm sept 