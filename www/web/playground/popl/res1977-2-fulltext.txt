machines with extended abstract a v s c johnson bell ill new jd princeton university princeton new operations summary previous work on optimal code generation has usually assumed that the underlying machine has identical registers and that all operands fit in a single register or memory location this paper considers the more realistic problem of generating optimal code for expressions involving single and double length operands using several models of machines both single and double word instructions with machines a new arises that is not present in optimal code generation for single register machines evaluation expression it may back and between evaluating subexpressions of the expression a optimal code generation algorithm is derived for a machine in which all registers are the algorithm is based on showing that for this model there is an optimal evaluation sequence with limited between the subtrees dominated by the children of a given node machine models including the familiar machine optimal evaluation sequences can always require introduction in programming languages rich in expressions like w or c we can find expressions containing many operators in generating good object code for these languages it is desirable to use registers to hold data and addresses consequently without care in the way available registers are used there may not always be enough registers available to evaluate expressions efficiently previous theoretical work on optimal code generation for expressions eg b n r has assumed that the underlying machine has n identical re that each data object in a single register or memory location and that all operators produce a result in a single register few real machines have such a simple register architecture many have special purpose registers for handling floating point operations integer multiplication and division addressing condition codes etc in this paper we make a into this world of by considering the influence of operand partially supported by nsf grant size and register structure on the complexity of code generation we relax the condition that data one register or memory location by allowing operands and results of instructions to have size single or double that is taking one or two registers or memory locations we shall call machines in which all instructions operate on operands machines with both single and double instructions will be called machines a precise definition of these machine models is contained in section of this paper this paper considers optimal code generation algorithms for machines in particular we are interested in the optimal evaluation of expressions having no common subexpressions when the expressions are represented they are trees rather than dags au we expressions with common subexpressions in this paper because in this case optimal code generation is already difficult even on single register machines bs with machines a new arises that is not present in optimal code generation for machines section shows that in an optimal evaluation of an expression on a machine it may always be necessary to back and between subexpressions of the expression this tion is in direct contrast to the property of optimal programs for machines aj for certain types of machines sections and show that we can bound this and thus derive a dynamic programming algorithm that generates optimal code for expressions in time that is linear in the input size of the expression for other types of register pair machines such as the machines section shows that this can be come arbitrarily large the machine model computers in existence present a of instruction certain operations such as multiplication and division often require double length data the precise details of these operations how ever vary widely from machine to machine the multiplication instruction for example may take as operands registers r and r and the result in the register pair r rl or in the register pair r or possibly in register r with the contents of register rl rather than considering an model which has sufficient complexity to every real machine we shall adopt a rather simple machine model in the hope that we can gain insight into the effects of the architecture of the underlying machine on the complexity of code generation we assume a machine has n registers io rl which are with respect to all instructions involving operands the in have the usual form r m load m r store operations here r and r refer to registers and m to a memory tion we also assume that there are instructions involving operands these instructions use two or two memory locations to hold an operand the re pairs that can be used to hold an operand are specified by a set p of register pairs for ex p might consist of all pairs r rl such that i is even the instructions have the following form r r ml ml double load m hi r r double store r r r r op s s r r r r op m ml r r r r op s sr r r r r r op s rs s r r op ml in these instructions r r and s s can be any register pairs in p and m ml is a pair of consecutive memory locations used to hold a operand note that in the operations the destination is always the same as the left operand if r r is a register pair in p we shall refer to r as the ei register of the pair and r as the right register to model real computers more closely we shall also permit classes of extend and operations of the fol form r r el r r r err r sl r r r sr r r where r r is any register pair in p finally we assume strong typing of operands we do not permit the use of a double load or double store to move two single values we shall consider three classes of machines in this paper these classes are distinguished by the set p of register pairs usable in in model p r r i oi j a model p r r i o model p r i o i sn although many other models are also possible these three serve to illustrate aspects of existing comput with instructions results to the unrestricted model can be used for machines where moves and are much faster than other operations the adjacent and models approximate machines such as the ibm system and the where somewhat similar restrictions are placed on what registers can be used to hold the operands of multiply and divide instructions f let us consider how an expression might be evaluated on an unrestricted machine with four registers r through r the tree for an expression with which we shall deal is shown in figure we use to represent single values and for a se of machine instructions evaluating tree with no stores is shown in figure this expression u it should be observed that the code of figure meets the restrictions of the adjacent machine but not the machine because e is loaded into an pair rather than an pair in fact there is no way to evaluate figure on a machine using a store instruction another important observation about the program of figure is that it begins working on the left subtree of the root then moves to the right subtree then back and figure expression tree tl r c load to r r r rl r r r i l b r r compute n i compute t rj r i ro ro g compute r r e r rj r compute tl r r compute ro rl a ro r ro compute rz rs el r r r r rh i compute t compute n i m r ro r compute figure machine code to evaluate figure i once more before evaluating the root this is necessary because if no stores are used h requires all four registers and requires three in fact al optimal programs evaluating figure on unrestricted register machines exhibit this behavior thus showing that this model does not satisfy the conditions for the theorem of it should be noted that the use of the is not essential for this example we could replace the subtrees of t and x by trees of requiring and registers respectively for evaluation with no stores and he same would appear in any optimal program using four registers limited in unrestricted machines this section shows that the required to evaluate an expression tree for an unrestricted machine can be confined to between the subtrees of the root this result is used in the next section to derive a dynamic programming algorithm for the generation of optimal code for an unrestricted machine the of an instruction in a program is the expression which that instruction computes the scope of an instruction is the subsequence of instructions from the instruction following up to the last instruction using the value of as a special case if f computes the root and is not then the scope of is to include the end of the program a value is at any instruction within its scope if the value of an instruction is never used that instruction is and its scope is empty the of a program is the maximum over all instructions of the number of live values held in registers after that instruction counting as and as except for all these notions are as in aj where more formal definitions appear there are two properties of optimal programs for machines that were used by to obtain a dynamic programming code generation algorithm which allows us to take any optimal program of width wand execute it using a fixed set of w registers that is registers can be renamed at will which allows us to take any op program for an expression tree range it into a sequence of p pl such that each p i r evaluates and stores into memory the value of some node of f evaluates the root of t except for the last instruction there are no other stores in p i r moreover for every node t the portion of the subtree of with root n that proper descendants of stored nodes is evaluated by a consecutive sequence of instructions in one of the ps n the unrestricted machine model the renaming tion continues to hold as all registers are equivalent in their capabilities the condition however fails to hold as we saw from example there is no op program which evaluates each subtree of the root of fig nevertheless we can prove the fol modified version for programs with no stores an obvious generalization analogous to the theorem of aj holds for programs with stores consider an expression tree t with root n having two subtrees t and t roughly speaking the following theorem states that if t can be evaluated with no stores then t can be evaluated by a program which has one of the following forms p pi p pp pi pp i p p p p p p p pp pp i pi and p evaluate subtrees t and t respectively leaving a result in a register and pi and p evaluate the remainder of t and t respectively i is the instruction evaluating the root tl thus an optimal program never needs more than two between t and t theorem let p be a program with no stores and no useless instructions computing some expression tree t on an unrestricted machine suppose the root of t has children c and c where c may not exist then for each of c and c which is double and has a descendant whose size is single we can select a node m which is a proper descendant of c such that m is single no proper ancestor of m except possibly the root of t is single we can find a program computing t with the same number of instructions as p of the same or smaller width as p and having the form p p pi where p js computes m or c into a register or registers and computes the root ­ moreover p is computed using at most n ­ x k where x k is if pk computes some c and there is no mf and xk is otherwise that is xj is the in in the number of registers needed to hold the results of pi p p over that needed to hold the results of p p we shall actually prove a somewhat stronger result by induction on the length of p the strengthening of the theorem necessary to form the inductive hypothesis is to permit p to compute t starting with the values of some leaves in registers provided these leaves each meet the above conditions l on the ms p may also start with the values of some of the cs in registers even if they are suppose the first instruction of p computes or loads a node n perhaps a leaf of the subtree of c the value of n is a double and at no time during the execution of p are fewer than two registers used for values in the subtree of c until the root is evaluated then using all n registers compute the value of c using the instructions of p that serve that purpose call this sequence of instructions pi and suppose without loss of generality that pi leaves its result in the last two registers and rename the registers in the remaining instructions of p so that only registers r through are used since at least two of the n registers are always to the subtree of c this renaming can be done let the resulting program be q by the inductive hypothesis we can put q in the form p p p i satisfying the conditions of the theorem and using n registers we may construct the desired pro gram pi p pl f by pi to pp p at some time during the computation of p only one ter is to values of descendants of c let n be the descendant of c whose value is in a register the last time in p that one register is to descendants of c it is not possible that some descendant of c was initially in a register when p or else condition in the theorem statement would be violated thus we may let pi be the subsequence of ps instructions computing tt into some register say n rename the registers used by the remaining instructions of p to avoid register until the value of m is used since at least one register is for a descendant of m until the value of m is used this renaming can be done apply the algorithm re to the remaining program and fl as be example consider the expression tree t in figure theorem implies that if t can be evaluated without stores then in the worst most case we can find ml and mj no proper ancestor of which is single such that an optimal program to evaluate t is never more complex than p p p p or where p and p are optimal programs to evaluate the subtrees of t with roots ml and n pi and p are optimal programs evaluating the left and right subtrees of the root r assuming ml and m have been evaluated and left in registers is the instruction evaluating the root r u p expression algorithm for unrestricted machines in this paper we measure the of a program in terms of the number of instructions used the results can be generalized to apply o more general additive cost if necessary theorem i us that in optimal way a tree involves working on each of the root in turn off work on a given subtree at once and leaving a single register holding u for that subtree if and when we do the dynamic programming approach of aj can now be applied provided we compute the following vectors for each node l the cost of computing some valued r of using i and later computing he of the tree with root r using j registers including the register used to hold the value of we can assume j since we could he entire tree with root without using j if the tree with root has no then a can be taken to be infinite tbe cost of computing the tree with root using registers if h is a leaf o for i to compute these values for a node h suppose the a and j values are available for its children we consider a list cl cz of children of the node such that each child appears at once and each child appears at most twice the list corresponds to an evaluation order in which the children which do not appear are assumed to have been computed and stored the children which appear once are to be completely computed at that time and the children which appear twice are assumed to have some singlevalued subtree computed and then later the entire subtree computed for each list we shall describe the contribution to f and t which might arise from computing the node in the way described in the list the actual costs a and lt will be the minimum over all lists of the con costs the contribution to each cost of a non child c not appearing in the list is the cost of it and storing it this is c plus the cost of a single or double store if c is the left descendant of h it must also be loaded so this cost must be included the contributions to a of a child c depend on whether it appears once or twice on the list and whether its sibling is a single or a double a few cases should illustrate what is involved the list is where c is a single the cost of his list is u ll l cl cost of the instruction for r this cost reflects a computation in which we first evaluate a subtree of c whose root is single with re available then compute the entire subtree whose root is with ­ registers available one being with he descendant of c then return to evaluate the remainder of the left subtree with ­ registers and finally evaluate h if is a double in this case then the first term in the cost is all cl the list is the cost of this list is u cost of the instruction for h here we evaluate a subtree of c with available registers evaluate a subtree of c with available registers complete the evaluation of c with ­ available registers then complete the evaluation of c with ­ available registers and finally evaluate similar formulas can be derived for the other cases the cost t is the minimum taken over a and the costs of the lists representing the ways of computing the tree with root without for example the list where both c and c are is cl b c cost of the instruction for h clearly given a list the time required to compute a and for a given i and j is bounded above by a constant for binary operators the number of lists is finite in fact lists have length at most applying the same kind of dynamic programming considerations as aj we can justify the following theorem there is an algorithm to generate optimal code for an unrestricted machine that is linear in the size of the expression o note that the above algorithm is quadratic in the number of registers if we permit operators of arbitrary i the complexity grows as k in effect this is the number of lists which must be considered models in which limited fails to hold the result of theorem implies a modified version of the theorem of which in turn implies a polynomial for optimal code generation how ever there are a number of machine models in which theorem can be shown no to hold that is two subtrees may be necessary for op evaluation of an expression for example consider the model for all u nd b with ub n we can construct a tree s which can be evaluated with no stores into a single register if and only if at least u pairs and b additional registers are available the case uo follows from the labeling algorithm of e ni the case bo follows similarly since i tree singlevalued operands requiring a can be made to require u register pairs by making all is operands and operators double and then he result if u and bo consider the of figure since b we can evaluate he side and store the result in ti register which is not part of the u pairs then evaluate he left if we could evaluate figure with no stores us ing fewer than u we would violate what we know about and if we used fewer ub in total we would what we know of sh u for every n there is an expression tree with a node two children c and c having the pro that any optimal program for on an machine with n registers has a subsequence of tions vl such that evaluate des of c and evaluate descendants of that is occur in the subtree of pro figure shows the tree consider a program for which does not store a result or move a value from one register to another any such program must be optimal we first evaluate so or we shall never be able to do so without stores must be computed an even register say register o for we shall eventual ly extend its value into the odd register if we do the extension now we can never evaluate since at least two registers will be up with the resulting value furthermore the result of sl must appear in register the other half of the above pair else there will not be sufficient to compute sn we are now in a situation where we cannot extend the value of in register o until we have computed the en right side of figure in this way by symmetry of we must compute s in ter v and sl i in register vl for ni n then we may compute s o in re we now use the remaining registers for s the result end up in register we then extend that value and the right side of figure in finally we may extend for n and evaluate and si into register the left side of fig and the root in registers o and thus every optimal program for times back and proving he theorem u it is interesting o observe that even the constraint we can produce subtrees to play the role of the ss in theorem for example if there are n registers the tree of figure can be evaluated with no stores only if the result up in thus if we permit trees like figure we can prove theorem pair machines d also holds for adjacent register summary and suggestions for further work we have considered several models of register pair machines and shown that there is an behavior to the optimal evaluation of expressions on these machines that is not present on single register machines for the unrestricted model we were able to bound the to two and thus derive a dynamic programming algorithm while the dynamic programming algorithm is too expensive to implement in most compiler applications its existence suggests a more specialized algorithm could be constructed for particular machines in this class for the and adjacent machines we showed the can be at least proportional to the number of registers this result suggests that efficient optimal algorithms if they exist are from any dynamic programming considerations to for these classes of machines there are a number of additional problems that would be worth solving to add to our understanding of code generation for machines is the optimal code generation problem polynomial or exponential for the a b adjacent register pair machines figure the tree ab er figure the tree for what other sets of register pairs p smaller than the unrestricted model does the limited theorem hold an interesting observation along these lines is that if there is one additional register ra which can only be used as the left pair of a double ie ro r rl r rl then is still required evaluation sions the trees behavior for theorems and produce a number of bounded by the number of registers is this the worst possible we if so it appears that optimal code generation could be done in time polynomial in the tree size but tial in the number of registers f we could bound the number of by some polynomial in the height of the tree the algorithm of section can be generalized to yield a polynomial algo rithm s there such a bound for the or cent machines how closely can optimality be approximated by a linear or polynomial algorithm for the or machines how well can we generate code for machines when expressions contain common sions a v aho and s c johnson optimal code generation for expression trees jacm july v aho s c johnson and j d code generation for expressions with common subexpressions jacm january to appear o sl a el ls el sl el i figure tree requiring n registers with the result in register v aho and j d straight line code unman m optimization j computing of b j c an axiomatic approach to code optimization for expressions oc bl j l and t the optimal code for stack machines generation of jacm j and r sethi machine code generation for a july e a p on programming of arithmetic operations a n translation in comm acm n on compiling algorithms for arithmetic expressions comm acm august r r r on arithmetic expressions and trees comm acm february m b w and m e the c programming language bell hill n j su r sethi and j d unman the generation of optimal code for arithmetic expressions jacm october w w r k c c s o and c m the qf ur compiler new york 